---
title: "Polyzogopoulos_Pavlos_BA_PT_Assignment3"
author: "pavlos"
date: "20 Δεκεμβρίου 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


```{r}
# QUESTION1 

df <- read.table ("C:/edo/usdata.sav", header = TRUE)
df
str(df) #6 variables int#
summary(df)
df$PRICE <- df$PRICE*100
df


### QUESTION 2 #

df[1:4] <- lapply(df[1:4], as.numeric)
df[5:6] <- lapply(df[5:6], as.factor)
str(df)

###Questions 3#

summary(df)
install.packages('psych')
require(psych)


index <- sapply(df, class) == "numeric"
dfnum <- df[,index]
round(t(describe(dfnum)),1)

#Visualization for numerical variables

dfnum
par(mfrow=c(2,2)); n <- nrow(dfnum)
hist(dfnum[,1], main=names(dfnum)[1])
hist(dfnum[,2], main=names(dfnum)[2])
plot(table(dfnum[,3])/n, type='h', xlim=range(dfnum[,3])+c(-1,1), main=names(dfnum)[3], ylab='Relative frequency')
plot(table(dfnum[,4])/n, type='h', xlim=range(dfnum[,4])+c(-1,1), main=names(dfnum)[4], ylab='Relative frequency')

# θα μπορούσαμε να πουμε ότι μόνο η μεταβλητή FEATS  ακολουθεί κανονική κατανομή 

#Visual Analysis for factors

dffac <- df[,!index]

par(mfrow=c(1,1))
barplot(sapply(dffac,table)/n, horiz=T, las=1, col=2:3, ylim=c(0,8), cex.names=1.3)
legend('top', fil=2:3, legend=c('No','Yes'), ncol=2, bty='n',cex=1.5)
#Τα περισσότερα σπίτια δεν βρίσκονται σε γωνιακή θέση (corner located) ενώ αντιθέτως τα περισσότερα από αυτά βρίσκονται στο βορειοανατολικό κομμάτι της πόλης

### Questions 4 #
install.packages("corrplot")
require(corrplot)

#take only pair for numeric variables
index <- sapply(df, class) == "numeric"
dfNum <- df[,index]
pairs(dfNum)

#Θα μπορούσαμε να πούμε ότι φαίνεται μία γραμμική συσχέτιση μεταξύ τιμής και SQFT

par(mfrow=c(2,2))
for(j in 2:4){
  plot(dfNum[,j], dfNum[,1], xlab=names(dfNum)[j], ylab='Price',cex.lab=1.5)
  abline(lm(dfNum[,1]~dfNum[,j]))
}

par(mfrow=c(1,3))
for(j in 2:4){
  boxplot(dfNum[,1]~dfNum[,j], xlab=names(dfNum)[j], ylab='Price',cex.lab=1.5)
  abline(lm(dfNum[,1]~dfNum[,j]),col=2)
}

#Θα μπορούσαμε να πούμε ότι φαίνεται μία γραμμική συσχέτιση μεταξύ τιμής και SQFT
#επίσης στο boxplot price-feats έχουμε 7 outliner 
#επίσης μετά από ένα σημείο όσο αυξλανεται η ηλικία μειώνεται η τιμή

### QUESTION 5 #

model1 <- lm(PRICE ~., data = dfnum) 
summary(model1) 
# φαίνεται ότι το age δεν ειναι στατιστικά σημαντικό 


model2 <- lm(PRICE ~. -AGE, data = dfnum)
summary(model2)   
#βελτιώνεται πολυ λίγο το R adj αλλά το intercept ακομα αρνητικο


model0 <- lm(PRICE ~ 1, data = dfnum)  
summary(model0) 

anova(model0, model1) 
# p value <0,05 οπότε τα extra μεταβλητές είναι σημαντικοι για τι μοντέλο μου 


model3 <- lm(PRICE~. - 1,data=dfnum) 
summary(model3) 

n <- nrow(dfnum)
1-sum(model3$res^2)/((n-1)*var(dfnum$PRICE)) 
#το πραγματικο R adj είναι λιγο μεγαλύτερο 


model4 <- lm(PRICE~.-AGE - 1,data=dfnum)     
summary(model4)

n <- nrow(dfnum)
1-sum(model4$res^2)/((n-1)*var(dfnum$PRICE))

#Μεχρι τωρα το καλυτερο μοντελο ειναι το 2 (δηλαδή χωρίς το age) αλλα το intercept ειναι αρνητικο 



dfnum2 <- as.data.frame(scale(dfnum, center = TRUE, scale = F))  ####center the covariates. θετιο το intercept και εξηγησιμο το μοντέλο
dfnum2$PRICE<-dfnum$PRICE
sapply(dfnum2,mean)
sapply(dfnum2,sd)
round(sapply(dfnum2,mean),5)
round(sapply(dfnum2,sd),2)
model5<-lm(PRICE~., data=dfnum2)
summary(model5)
round(summary(model5)$coef, 2)

model6 <- lm(PRICE~. -AGE, data=dfnum2)   
summary(model6)   
round(summary(model6)$coef, 2)


#Aρα έχω καταλήξει μέχρι στιγμής στο μοντέλο
#  PRICE = 115.841,27 + 68,05*SQFT + 3983,69*FEATS + ε  /  ε ~ Ν( 0, 14370^2)



# προσθέτω τα categoricals variables  

model7<-lm(PRICE~., data=df)
summary(model7) 
#παλι απο R βλέπουμε ότι ειναι ελαχιστα καλυτερο το προηγουμενο μοντελο και επισης τα age, ne and cor ειναι insignificant
# επισης αυξάνεται και το residual standard error

anova(model1, model2, model7)
# p values >0,05 άρα οι extra μετβλητές  δεν ειναι στατιστικά σημαντικές 


x <- model.matrix(model7)   
x



### Questions 6 #

#Stepwise procedure

#Forward

mfull <- lm(df$PRICE~.,data=df)
mnull <- lm(df$PRICE~1,data=df)
step(mnull, scope=list(lower=mnull,upper=mfull), direction='forward')
summary(step(mnull, direction = 'forward'))

#Both
mfull <- lm(df$PRICE~.,data=df)
mnull <- lm(df$PRICE~1,data=df)
step(mnull, scope=list(lower=mnull,upper=mfull), direction='both')
summary(step(mfull, direction='both')) 

summary( step( mfull, direction='both',k=log(100) ) )


install.packages('leaps')
require(leaps)
plot(regsubsets(df$PRICE ~ ., data = df, nvmax = 15, nbest = 1))

#Using BAS 
install.packages('BAS')
require(BAS)
bas.results <- bas.lm(df$PRICE ~ ., data = df, prior = "BIC")
image(bas.results)

bas.results <- bas.lm(df$PRICE ~ .,data = df, prior = "AIC")

# H μέθοδος stepwise μου έδειξε πως πρέπει να κρατήσω τι; μεταβλητές SQFT και FEATS 
# H διαφορά στο intercept προέκυψε επειδή στο αρχικό μοντέλο είχα κάνει centered τα covariates 
# Οπότε θα κρατήσω το model6 το οποίο περιέχει αυτες τις μεταβλητές , έχει centered τα covariates και το intercept είναι θετικό αλλά και ταυτόχρονα στατιστικά σημαντικό 
# ’ρα PRICE = 115.841,27 + 68,05*SQFT + 3983,69*FEATS + ε  /  ε ~ Ν( 0, 14370^2) 
# ’ρα καταλήγω πως η τιμή για ένα μέσο σπίτι με μέσα χαρακτηριστικά έχει αξία 115.841,27$ (τα έχω μετατρέψει από houndreds) 
# Εάν αυξηθούν τα τμ κατά 1 μονάδα τότε και η τιμή για ένα μέσο σπίτι (με τα FEATS σταθερά) θα αυξηθεί κατά 68,05$ 
# Εάν αυξηθούν τα FEATS κατά 1 τότε και η τιμή για ένα μέσο σπίτι (με τα SQFT σταθερά) θα αυξηθεί κατά 3,983,69$ 

#QUESTION 8 #

#Checking the assumptions

final_model<- lm(PRICE ~.-AGE, data = dfnum2)
summary(final_model)

library(car)
vif(final_model)
# καμία μεταβλητή δεν ξεπερνάει το 10 

#Normality of the residuals
plot(final_model, which = 2) 
# Φαίνεται να υπάρχει πρόβλημα στις <ουρές> 

#Costant variance 
Stud.residuals <- rstudent(final_model)
yhat <- fitted(final_model)
par(mfrow=c(1,2))
plot(yhat, Stud.residuals)
abline(h=c(-2,2), col=2, lty=2)
plot(yhat, Stud.residuals^2)
abline(h=4, col=2, lty=2)
# Υπάρχουν τιμές πάνω από την γραμμή 

install.packages('car')
library(car)
ncvTest(final_model)
# p-value=0.0001078522<0.05 

yhat.quantiles<-cut(yhat, breaks=quantile(yhat, probs=seq(0,1,0.25)), dig.lab=6)
table(yhat.quantiles)
leveneTest(rstudent(final_model)~yhat.quantiles)
boxplot(rstudent(final_model)~yhat.quantiles)
# p-value=2.249e-05<0.05
# non linearity
library(car)
par(mfrow=c(1,1))
residualPlot(final_model, type='rstudent')
residualPlots(final_model, plot=F)
# δεν είναι ευθεία η γραμμή

# Independence 
plot(rstudent(final_model), type='l')
library(randtests); runs.test(final_model$res)
library(lmtest);dwtest(final_model)
library(car); durbinWatsonTest(final_model)

#from all the above, we can infer that it would helpful if we logged our final model, because logarithms may correct the problem
#Από όλα τα παραπάνω συμπεραίνουμε ότι υπάρχει πρόβλημα με τα αρχικά assumptions 
# Ίσως χρησιμοποιώντας τα log των μεταβλητών ή τα πολυώνυμα να λυνόταν το πρόβλημα της Multi???collinearity 

### QUESTION 9 #

install.packages('glmnet')
require(glmnet)
mfull <- lm(df$PRICE~.,data=df)
#As the l increases, lasso shrinks the mfull <- lm(df$PRICE~.,data=df)
X <- model.matrix(mfull)[,-1]
lasso <- glmnet(X, df$PRICE)
plot(lasso, xvar = "lambda", label = T)

lasso1 <- cv.glmnet(X, df$PRICE, alpha = 1)
lasso1$lambda
lasso1$lambda.min 
#choose the essential predictors with the lowest square error.
lasso1$lambda.1se 
#leads to a model that is not quite the lowest. it is one standard error away from the minimun
#Choose the second --> has less predictor but you dont lose occuracy
plot(lasso1)
#to find the final model to the following command:
#the dot in the matrix mean that they excluded
coef(lasso1, s = "lambda.min")
coef(lasso1, s = "lambda.1se")
plot(lasso1$glmnet.fit, xvar = "lambda")
abline(v=log(c(lasso1$lambda.min, lasso1$lambda.1se)), lty =2)
```








